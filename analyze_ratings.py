#!/usr/bin/env python3
"""
ICLR 2026 è¯„åˆ†æ•°æ®æ·±åº¦åˆ†æ
åˆ†ææ‰€æœ‰è®ºæ–‡çš„è¯„åˆ†åˆ†å¸ƒã€ç»Ÿè®¡ç‰¹å¾å’Œè¶‹åŠ¿
"""

import json
import statistics
from collections import Counter, defaultdict

def load_ratings_data(filepath):
    """åŠ è½½è¯„åˆ†æ•°æ®"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None

def basic_statistics(ratings_data):
    """åŸºç¡€ç»Ÿè®¡åˆ†æ"""
    print("=" * 60)
    print("ğŸ“Š ICLR 2026 è¯„åˆ†æ•°æ®åŸºç¡€ç»Ÿè®¡")
    print("=" * 60)

    total_papers = len(ratings_data)
    total_ratings = sum(paper['reviewer_count'] for paper in ratings_data)

    # æå–æ‰€æœ‰è¯„åˆ†ç”¨äºåˆ†æ
    all_ratings = []
    avg_ratings = []
    min_ratings = []
    max_ratings = []
    reviewer_counts = []

    for paper in ratings_data:
        all_ratings.extend(paper['ratings'])
        avg_ratings.append(paper['avg_rating'])
        min_ratings.append(paper['min_rating'])
        max_ratings.append(paper['max_rating'])
        reviewer_counts.append(paper['reviewer_count'])

    print(f"ğŸ“„ æ€»è®ºæ–‡æ•°é‡: {total_papers:,} ç¯‡")
    print(f"â­ æ€»è¯„åˆ†æ•°é‡: {total_ratings:,} ä¸ª")
    print(f"ğŸ“Š å¹³å‡è¯„åˆ†: {statistics.mean(all_ratings):.2f}")
    print(f"ğŸ“ˆ è¯„åˆ†ä¸­ä½æ•°: {statistics.median(all_ratings):.2f}")
    print(f"ğŸ“‰ è¯„åˆ†æ ‡å‡†å·®: {statistics.stdev(all_ratings):.2f}")
    print(f"ğŸ”¢ è¯„åˆ†èŒƒå›´: {min(all_ratings)} - {max(all_ratings)}")
    print()

    print("ğŸ“‹ å¹³å‡åˆ†ç»Ÿè®¡:")
    print(f"  å¹³å‡åˆ†å‡å€¼: {statistics.mean(avg_ratings):.2f}")
    print(f"  å¹³å‡åˆ†ä¸­ä½æ•°: {statistics.median(avg_ratings):.2f}")
    print(f"  å¹³å‡åˆ†æ ‡å‡†å·®: {statistics.stdev(avg_ratings):.2f}")
    print(f"  å¹³å‡åˆ†èŒƒå›´: {min(avg_ratings):.2f} - {max(avg_ratings):.2f}")
    print()

    print("ğŸ“ˆ æœ€é«˜åˆ†å’Œæœ€ä½åˆ†ç»Ÿè®¡:")
    print(f"  æœ€ä½åˆ†å‡å€¼: {statistics.mean(min_ratings):.2f}")
    print(f"  æœ€é«˜åˆ†å‡å€¼: {statistics.mean(max_ratings):.2f}")
    print()

    print("ğŸ‘¥ è¯„å®¡äººæ•°ç»Ÿè®¡:")
    print(f"  å¹³å‡è¯„å®¡äººæ•°: {statistics.mean(reviewer_counts):.2f}")
    print(f"  è¯„å®¡äººæ•°èŒƒå›´: {min(reviewer_counts)} - {max(reviewer_counts)}")

    return {
        'all_ratings': all_ratings,
        'avg_ratings': avg_ratings,
        'min_ratings': min_ratings,
        'max_ratings': max_ratings,
        'reviewer_counts': reviewer_counts
    }

def rating_distribution_analysis(all_ratings):
    """è¯„åˆ†åˆ†å¸ƒåˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ è¯„åˆ†åˆ†å¸ƒåˆ†æ")
    print("=" * 60)

    rating_counter = Counter(all_ratings)
    total_ratings = len(all_ratings)

    print("ğŸ“Š å„åˆ†æ•°æ®µåˆ†å¸ƒ:")
    for rating in sorted(rating_counter.keys()):
        count = rating_counter[rating]
        percentage = (count / total_ratings) * 100
        bar_length = int(percentage / 2)  # ç¼©æ”¾åˆ°åˆé€‚é•¿åº¦
        bar = "â–ˆ" * bar_length + "â–‘" * (25 - bar_length)
        print(f"  {rating:2d}åˆ†: {count:6,} ({percentage:5.1f}%) |{bar}|")

    print("\nğŸ“‹ è¯„åˆ†åˆ†ç»„ç»Ÿè®¡:")
    groups = {
        '0åˆ†': rating_counter[0],
        '2åˆ†': rating_counter[2],
        '4åˆ†': rating_counter[4],
        '6åˆ†': rating_counter[6],
        '8åˆ†': rating_counter[8],
        '10åˆ†': rating_counter[10]
    }

    for group, count in groups.items():
        percentage = (count / total_ratings) * 100
        print(f"  {group}: {count:,} ({percentage:.1f}%)")

def avg_rating_distribution_analysis(avg_ratings):
    """å¹³å‡åˆ†åˆ†å¸ƒåˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å¹³å‡åˆ†åˆ†å¸ƒåˆ†æ")
    print("=" * 60)

    # åˆ†æ®µç»Ÿè®¡
    ranges = {
        "0.0-1.9": 0, "2.0-2.9": 0, "3.0-3.9": 0, "4.0-4.9": 0,
        "5.0-5.9": 0, "6.0-6.9": 0, "7.0-7.9": 0, "8.0-8.5": 0
    }

    for avg in avg_ratings:
        if 0.0 <= avg <= 1.9:
            ranges["0.0-1.9"] += 1
        elif 2.0 <= avg <= 2.9:
            ranges["2.0-2.9"] += 1
        elif 3.0 <= avg <= 3.9:
            ranges["3.0-3.9"] += 1
        elif 4.0 <= avg <= 4.9:
            ranges["4.0-4.9"] += 1
        elif 5.0 <= avg <= 5.9:
            ranges["5.0-5.9"] += 1
        elif 6.0 <= avg <= 6.9:
            ranges["6.0-6.9"] += 1
        elif 7.0 <= avg <= 7.9:
            ranges["7.0-7.9"] += 1
        elif 8.0 <= avg <= 8.5:
            ranges["8.0-8.5"] += 1

    total_papers = len(avg_ratings)
    print("ğŸ“ˆ å¹³å‡åˆ†åŒºé—´åˆ†å¸ƒ:")
    for range_name, count in ranges.items():
        percentage = (count / total_papers) * 100
        bar_length = int(percentage / 2)
        bar = "â–ˆ" * bar_length + "â–‘" * (25 - bar_length)
        print(f"  {range_name}: {count:4,} ({percentage:5.1f}%) |{bar}|")

def reviewer_analysis(reviewer_counts):
    """è¯„å®¡äººæ•°åˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ‘¥ è¯„å®¡äººæ•°åˆ†æ")
    print("=" * 60)

    reviewer_counter = Counter(reviewer_counts)
    total_papers = len(reviewer_counts)

    print("ğŸ“Š è¯„å®¡äººæ•°åˆ†å¸ƒ:")
    for num_reviewers in sorted(reviewer_counter.keys()):
        count = reviewer_counter[num_reviewers]
        percentage = (count / total_papers) * 100
        print(f"  {num_reviewers}ä½è¯„å®¡: {count:4,}ç¯‡è®ºæ–‡ ({percentage:5.1f}%)")

def high_rated_papers_analysis(avg_ratings):
    """é«˜è¯„åˆ†è®ºæ–‡åˆ†æ"""
    print("\n" + "=" * 60)
    print("â­ é«˜è¯„åˆ†è®ºæ–‡åˆ†æ")
    print("=" * 60)

    # å®šä¹‰é«˜è¯„åˆ†æ ‡å‡†
    high_rated = [avg for avg in avg_ratings if avg >= 6.0]
    very_high_rated = [avg for avg in avg_ratings if avg >= 8.0]

    print(f"ğŸ“ˆ å¹³å‡åˆ†â‰¥6.0çš„è®ºæ–‡: {len(high_rated):,}ç¯‡ ({len(high_rated)/len(avg_ratings)*100:.1f}%)")
    print(f"ğŸ“ˆ å¹³å‡åˆ†â‰¥8.0çš„è®ºæ–‡: {len(very_high_rated):,}ç¯‡ ({len(very_high_rated)/len(avg_ratings)*100:.1f}%)")

    # æ‰¾å‡ºæœ€é«˜åˆ†è®ºæ–‡
    max_rating = max(avg_ratings)
    max_count = sum(1 for avg in avg_ratings if avg == max_rating)
    print(f"ğŸ† æœ€é«˜å¹³å‡åˆ†: {max_rating:.2f}åˆ† ({max_count}ç¯‡è®ºæ–‡)")

    # ç»Ÿè®¡å„ä¸ªé«˜åˆ†æ®µ
    score_ranges = {
        "6.0-6.9": sum(1 for avg in avg_ratings if 6.0 <= avg < 7.0),
        "7.0-7.9": sum(1 for avg in avg_ratings if 7.0 <= avg < 8.0),
        "8.0-8.5": sum(1 for avg in avg_ratings if 8.0 <= avg <= 8.5)
    }

    print("\nğŸ“Š é«˜åˆ†æ®µåˆ†å¸ƒ:")
    for range_name, count in score_ranges.items():
        percentage = (count / len(avg_ratings)) * 100
        print(f"  {range_name}åˆ†: {count:,}ç¯‡ ({percentage:.1f}%)")

def extreme_cases_analysis(ratings_data):
    """æç«¯æ¡ˆä¾‹åˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ¯ æç«¯æ¡ˆä¾‹åˆ†æ")
    print("=" * 60)

    # æ‰¾å‡ºè¯„åˆ†æœ€é«˜å’Œæœ€ä½çš„è®ºæ–‡
    highest_rated = max(ratings_data, key=lambda x: x['avg_rating'])
    lowest_rated = min(ratings_data, key=lambda x: x['avg_rating'])

    print("ğŸ† è¯„åˆ†æœ€é«˜è®ºæ–‡:")
    print(f"  è®ºæ–‡ID: {highest_rated['paper_id']}")
    print(f"  å¹³å‡åˆ†: {highest_rated['avg_rating']:.2f}")
    print(f"  è¯„åˆ†èŒƒå›´: {highest_rated['min_rating']} - {highest_rated['max_rating']}")
    print(f"  è¯„å®¡äººæ•°: {highest_rated['reviewer_count']}")
    print(f"  è¯¦ç»†è¯„åˆ†: {highest_rated['ratings']}")

    print("\nğŸ“‰ è¯„åˆ†æœ€ä½è®ºæ–‡:")
    print(f"  è®ºæ–‡ID: {lowest_rated['paper_id']}")
    print(f"  å¹³å‡åˆ†: {lowest_rated['avg_rating']:.2f}")
    print(f"  è¯„åˆ†èŒƒå›´: {lowest_rated['min_rating']} - {lowest_rated['max_rating']}")
    print(f"  è¯„å®¡äººæ•°: {lowest_rated['reviewer_count']}")
    print(f"  è¯¦ç»†è¯„åˆ†: {lowest_rated['ratings']}")

    # æ‰¾å‡ºè¯„å®¡äººæ•°æœ€å¤šå’Œæœ€å°‘çš„è®ºæ–‡
    most_reviewed = max(ratings_data, key=lambda x: x['reviewer_count'])
    least_reviewed = min(ratings_data, key=lambda x: x['reviewer_count'])

    print(f"\nğŸ‘¥ è¯„å®¡äººæ•°æœ€å¤š: {most_reviewed['reviewer_count']}ä½è¯„å®¡ (è®ºæ–‡ID: {most_reviewed['paper_id']})")
    print(f"ğŸ‘¤ è¯„å®¡äººæ•°æœ€å°‘: {least_reviewed['reviewer_count']}ä½è¯„å®¡ (è®ºæ–‡ID: {least_reviewed['paper_id']})")

def quality_indicators_analysis(ratings_data):
    """è´¨é‡æŒ‡æ ‡åˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ è´¨é‡æŒ‡æ ‡åˆ†æ")
    print("=" * 60)

    # è®¡ç®—å„ç§è´¨é‡æŒ‡æ ‡
    consistent_papers = []  # è¯„åˆ†ä¸€è‡´çš„è®ºæ–‡
    controversial_papers = []  # è¯„åˆ†å·®å¼‚å¤§çš„è®ºæ–‡

    for paper in ratings_data:
        ratings = paper['ratings']
        if len(set(ratings)) == 1:  # æ‰€æœ‰è¯„åˆ†ç›¸åŒ
            consistent_papers.append(paper)
        elif paper['max_rating'] - paper['min_rating'] >= 6:  # è¯„åˆ†å·®å¼‚â‰¥6åˆ†
            controversial_papers.append(paper)

    print(f"âœ… è¯„åˆ†å®Œå…¨ä¸€è‡´è®ºæ–‡: {len(consistent_papers):,}ç¯‡ ({len(consistent_papers)/len(ratings_data)*100:.1f}%)")
    print(f"âš¡ è¯„åˆ†å·®å¼‚â‰¥6åˆ†è®ºæ–‡: {len(controversial_papers):,}ç¯‡ ({len(controversial_papers)/len(ratings_data)*100:.1f}%)")

    # åˆ†æè¯„åˆ†å·®å¼‚åˆ†å¸ƒ
    rating_spreads = [paper['max_rating'] - paper['min_rating'] for paper in ratings_data]
    print(f"\nğŸ“Š è¯„åˆ†å·®å¼‚ç»Ÿè®¡:")
    print(f"  å¹³å‡è¯„åˆ†å·®å¼‚: {statistics.mean(rating_spreads):.2f}åˆ†")
    print(f"  ä¸­ä½æ•°è¯„åˆ†å·®å¼‚: {statistics.median(rating_spreads):.2f}åˆ†")
    print(f"  æœ€å¤§è¯„åˆ†å·®å¼‚: {max(rating_spreads)}åˆ†")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ICLR 2026 è¯„åˆ†æ•°æ®æ·±åº¦åˆ†ææŠ¥å‘Š")
    print("=" * 80)

    # åŠ è½½æ•°æ®
    ratings_data = load_ratings_data('./data/iclr26_ratings.json')
    if not ratings_data:
        return

    print(f"âœ… æˆåŠŸåŠ è½½ {len(ratings_data)} ç¯‡è®ºæ–‡çš„è¯„åˆ†æ•°æ®")

    # åŸºç¡€ç»Ÿè®¡åˆ†æ
    stats_data = basic_statistics(ratings_data)

    # è¯¦ç»†åˆ†æ
    rating_distribution_analysis(stats_data['all_ratings'])
    avg_rating_distribution_analysis(stats_data['avg_ratings'])
    reviewer_analysis(stats_data['reviewer_counts'])
    high_rated_papers_analysis(stats_data['avg_ratings'])
    extreme_cases_analysis(ratings_data)
    quality_indicators_analysis(ratings_data)

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("=" * 80)

if __name__ == "__main__":
    main()